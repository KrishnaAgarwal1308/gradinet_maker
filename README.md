Gradient Decent is the backbone of any ml training.
This repository shows how gradient decent works under the hood in pytorch or any other framework.

It doesnot requires any fancy framework here to run and understand the code. It just requires prior knowledge of high school level calculus and a good understanding of python(OOPs).

How to go through this repository?
1. nn.py contains a MLP training example using a very simple data set which is easy to visualize and the gradient decent is done by using the file gradient_maker.py
2. gradient_maker.py contains the classes and function to define a function and how to do gradient decent in it, it uses graph structure to store the gradients of different nodes connecting each other.
